#! /usr/bin/env python

import traceback
import sys
import os
import stat
import errno
from datetime import datetime

# pull in some spaghetti to make this stuff work without fuse-py being installed
try:
    import _find_fuse_parts
except ImportError:
    pass

import fuse
from fuse import Fuse

if not hasattr(fuse, '__version__'):
    raise RuntimeError, \
        "your fuse-py doesn't know of fuse.__version__, probably it's too old."

fuse.fuse_python_api = (0, 2)

fuse.feature_assert('stateful_files', 'has_init')

__version__ = '0.01'

class SQL :
    '''
    Holds all SQL statements used by baculafs
    '''

    clients = 'SELECT Client.Name,ClientId FROM Client'
    
    filesets = '''
    SELECT DISTINCT FileSet.FileSet FROM Job,
    Client,FileSet WHERE Job.FileSetId=FileSet.FileSetId
    AND Job.ClientId=%s AND Client.ClientId=%s 
    ORDER BY FileSet.FileSet
    '''

    fileset = '''
    SELECT FileSetId,FileSet,MD5,CreateTime FROM FileSet
    WHERE FileSet="%s" ORDER BY CreateTime DESC LIMIT 1
    '''

    create_temp = '''
    CREATE TEMPORARY TABLE temp (
    JobId INTEGER UNSIGNED NOT NULL,
    JobTDate BIGINT UNSIGNED,
    ClientId INTEGER UNSIGNED,
    Level CHAR,
    JobFiles INTEGER UNSIGNED,
    JobBytes BIGINT UNSIGNED,
    StartTime TEXT,
    VolumeName TEXT,
    StartFile INTEGER UNSIGNED,
    VolSessionId INTEGER UNSIGNED,
    VolSessionTime INTEGER UNSIGNED)
    '''

    create_temp1 = '''
    CREATE TEMPORARY TABLE temp1 (
    JobId INTEGER UNSIGNED NOT NULL,
    JobTDate BIGINT UNSIGNED)
    '''

    temp  = 'SELECT * FROM temp'

    temp1 = 'SELECT * FROM temp1'

    del_temp = 'DROP TABLE temp'
    
    del_temp1 = 'DROP TABLE temp1'

    full_jobs_temp1 = '''
    INSERT INTO temp1 SELECT Job.JobId,JobTdate 
    FROM Client,Job,JobMedia,Media,FileSet WHERE Client.ClientId=%s
    AND Job.ClientId=%s
    AND Job.StartTime < DATETIME("%s")
    AND Level='F' AND JobStatus IN ('T','W') AND Type='B' 
    AND JobMedia.JobId=Job.JobId 
    AND Media.Enabled=1 
    AND JobMedia.MediaId=Media.MediaId 
    AND Job.FileSetId=FileSet.FileSetId 
    AND FileSet.FileSet="%s"
    ORDER BY Job.JobTDate DESC LIMIT 1
    '''

    full_jobs_temp = '''
    INSERT INTO temp SELECT Job.JobId,Job.JobTDate,
    Job.ClientId,Job.Level,Job.JobFiles,Job.JobBytes,
    StartTime,VolumeName,JobMedia.StartFile,VolSessionId,VolSessionTime 
    FROM temp1,Job,JobMedia,Media WHERE temp1.JobId=Job.JobId 
    AND Level='F' AND JobStatus IN ('T','W') AND Type='B' 
    AND Media.Enabled=1 
    AND JobMedia.JobId=Job.JobId 
    AND JobMedia.MediaId=Media.MediaId
    '''

    diff_jobs_temp = '''
    INSERT INTO temp SELECT Job.JobId,Job.JobTDate,Job.ClientId,
    Job.Level,Job.JobFiles,Job.JobBytes,
    Job.StartTime,Media.VolumeName,JobMedia.StartFile,
    Job.VolSessionId,Job.VolSessionTime 
    FROM Job,JobMedia,Media,FileSet 
    WHERE Job.JobTDate>%d AND Job.StartTime<DATETIME("%s")
    AND Job.ClientId=%d 
    AND JobMedia.JobId=Job.JobId 
    AND Media.Enabled=1 
    AND JobMedia.MediaId=Media.MediaId 
    AND Job.Level='D' AND JobStatus IN ('T','W') AND Type='B' 
    AND Job.FileSetId=FileSet.FileSetId 
    AND FileSet.FileSet="%s"
    ORDER BY Job.JobTDate DESC LIMIT 1
    '''

    incr_jobs_temp = '''
    INSERT INTO temp SELECT Job.JobId,Job.JobTDate,Job.ClientId,
    Job.Level,Job.JobFiles,Job.JobBytes,
    Job.StartTime,Media.VolumeName,JobMedia.StartFile,
    Job.VolSessionId,Job.VolSessionTime 
    FROM Job,JobMedia,Media,FileSet 
    WHERE Job.JobTDate>%d AND Job.StartTime<DATETIME("%s") 
    AND Job.ClientId=%d
    AND Media.Enabled=1 
    AND JobMedia.JobId=Job.JobId 
    AND JobMedia.MediaId=Media.MediaId 
    AND Job.Level='I' AND JobStatus IN ('T','W') AND Type='B' 
    AND Job.FileSetId=FileSet.FileSetId 
    AND FileSet.FileSet="%s"
    '''

    jobs = 'SELECT DISTINCT JobId,StartTime FROM temp ORDER BY StartTime ASC'

    base_jobs = '''
    SELECT DISTINCT BaseJobId
    FROM Job JOIN BaseFiles USING (JobId)
    WHERE Job.HasBase = 1
    AND Job.JobId IN (%s)
    '''

    purged_jobs = '''
    SELECT SUM(PurgedFiles) FROM Job WHERE JobId IN (%s)
    '''
    
    files = '''
    SELECT Path.Path, Filename.Name, Temp.FileIndex, Temp.JobId, LStat, MD5 
     FROM ( %s ) AS Temp 
     JOIN Filename ON (Filename.FilenameId = Temp.FilenameId) 
     JOIN Path ON (Path.PathId = Temp.PathId) 
    WHERE FileIndex > 0 
    ORDER BY Temp.JobId, FileIndex ASC
    '''

    with_basejobs = '''
    SELECT FileId, Job.JobId AS JobId, FileIndex, File.PathId AS PathId, 
           File.FilenameId AS FilenameId, LStat, MD5 
    FROM Job, File, ( 
        SELECT MAX(JobTDate) AS JobTDate, PathId, FilenameId 
          FROM ( 
            SELECT JobTDate, PathId, FilenameId 
              FROM File JOIN Job USING (JobId) 
             WHERE File.JobId IN (%s) 
              UNION ALL 
            SELECT JobTDate, PathId, FilenameId 
              FROM BaseFiles 
                   JOIN File USING (FileId) 
                   JOIN Job  ON    (BaseJobId = Job.JobId) 
             WHERE BaseFiles.JobId IN (%s) 
           ) AS tmp GROUP BY PathId, FilenameId 
        ) AS T1 
    WHERE (Job.JobId IN ( 
             SELECT DISTINCT BaseJobId FROM BaseFiles WHERE JobId IN (%s)) 
            OR Job.JobId IN (%s)) 
      AND T1.JobTDate = Job.JobTDate 
      AND Job.JobId = File.JobId 
      AND T1.PathId = File.PathId 
      AND T1.FilenameId = File.FilenameId
    '''

class Base64 :
    '''
    Bacula specific implementation of a base64 decoder
    '''
    digits = [
        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',
        'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
        'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',
        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '/'
        ]

    def __init__(self) :
        '''
        Initialize the Base 64 conversion routines
        '''
        self.base64_map = dict(zip(Base64.digits,xrange(0,64)))
    
    def decode(self, base64) :
        '''
        Convert the Base 64 characters in base64 to a value.
        '''
        value = 0
        first = 0
        neg = False

        if base64[0] == '-' :
            neg = True
            first = 1
            
        for i in xrange(first, len(base64)) :
            value = value << 6
            value += self.base64_map[base64[i]]

        return -value if neg else value
    
class Database :
    '''
    This class shields the rest of the code from the pesky details of
    actually accessing one of the supported databases.
    '''
    def __init__(self, driver, database, username, password, verbose) :
        '''
        Initialize database driver: connect the database,
        create connection and cusror objects.
        '''
        self.verbose = verbose
        self.connection = None
        self.cursor = None
        if driver == 'sqlite3' :
            from sqlite3 import connect
            database = os.path.expanduser(database)
            if not os.path.isfile(database) or not os.access(database, os.R_OK) :
                raise RuntimeError, 'cannot read from file %s' % database
            self.connection = connect(database)
            self.connection.text_factory = str # fixes sqlite3.OperationalError: Could not decode to UTF-8
            self.cursor = self.connection.cursor()
        else :
            raise ValueError, 'driver %s not supported yet.' % driver

    def __del__(self) :
        '''
        Close database connection
        '''
        if self.cursor :
            self.cursor.close()
        if self.connection :
            self.connection.close()

    def query(self, sql) :
        '''
        Execute SQL and fetch all results
        '''
        if self.verbose :
            print sql
        self.cursor.execute(sql)
        return self.cursor.fetchall()
        
    
    
class Catalog :
    '''
    This class represents the Bacula catalog, and provides an interface
    for generating a list of files for a given set of user supplied
    query parameters.
    '''
    def __init__(self, database) :
        '''
        Catalog initialization: DATABASE is a Database driver
        object.
        '''
        self.db = database

        
    def query(self, client, fileset = None, timespec = None, volume = None) :
        '''
        Query bacula database, get list of files that match
        backup prior to given TIMESPEC, for a given CLIENT, FILESET
        and VOLUME.

        If the date/time is not specified (i.e. it's None) then use
        the current date/time.

        File records include file path, file name, stat info and
        restore info.

        Security note: query parameters are never taken from user supplied
        input, but rather are verified against the catalog. This allows us to
        use formatted strings for building parametrized queries.
        '''
        # validate client
        self.clients = dict(self.db.query(SQL.clients))
        if client not in self.clients :
            raise ValueError, 'client must be one of %s' % self.clients.keys()
        self.client_id = self.clients[client]
        # validate fileset
        self.filesets = [f[0] for f in self.db.query(SQL.filesets % (self.client_id, self.client_id))]
        if len(self.filesets) == 1 and not fileset :
            fileset = self.filesets[0]
        elif len(self.filesets) == 0 :
            raise RuntimeError, 'no filesets found for %s' % client
        elif fileset not in self.filesets :
            raise ValueError, 'fileset must be one of %s' % self.filesets
        self.fileset = self.db.query(SQL.fileset % fileset)[0]
        # validate timespec
        if timespec :
            self.datetime = datetime.isoformat(datetime.strptime(timespec, '%Y-%m-%d %H:%M:%S'))
        else :
            self.datetime = str(datetime.now())
        # create temporary tables
        self.db.query(SQL.create_temp)
        self.db.query(SQL.create_temp1)
        # get list of jobs
        self.db.query(SQL.full_jobs_temp1 %
                            (self.client_id, self.client_id, self.datetime, self.fileset[1]))
        self.db.query(SQL.full_jobs_temp)
        full_jobs = self.db.query(SQL.temp1)
        if len(full_jobs) == 0 :
            raise RuntimeError, 'no full jobs found'
        self.db.query(SQL.diff_jobs_temp % (full_jobs[0][1], self.datetime, self.client_id, self.fileset[1]))
        diff_jobs = self.db.query(SQL.temp)
        self.db.query(SQL.incr_jobs_temp % (diff_jobs[-1][1], self.datetime, self.client_id, self.fileset[1]))
        self.jobs = self.db.query(SQL.jobs)
        jobs_csl = ','.join([str(job[0]) for job in self.jobs])
        base_jobs = self.db.query(SQL.base_jobs % jobs_csl)
        all_jobs_csl = ','.join([str(job[0]) for job in self.jobs + base_jobs])
        # abort if any job in the list has been purged
        purged = self.db.query(SQL.purged_jobs % all_jobs_csl)
        if purged[0][0] > 0 :
            raise RuntimeError, 'purged jobs in list (%s)' % all_jobs_csl
        # get files
        self.files = self.db.query(SQL.files % (SQL.with_basejobs % (jobs_csl, jobs_csl, jobs_csl, jobs_csl)))
        # delete temporary tables
        self.db.query(SQL.del_temp)
        self.db.query(SQL.del_temp1)

        return self.files


class FileSystem(Fuse) :

    null_stat = fuse.Stat(st_mode = stat.S_IFDIR | 0755, st_nlink = 2)

    bacula_stat_fields = ['st_dev',
                          'st_ino',
                          'st_mode',
                          'st_nlink',
                          'st_uid',
                          'st_gid',
                          'st_rdev',
                          'st_size',
                          'st_blksize',
                          'st_blocks',
                          'st_atime',
                          'st_mtime',
                          'st_ctime',
                          'st_linkfi',
                          'st_flags',
                          'st_streamid']

    fuse_stat_fields = dir(fuse.Stat())

    def __init__(self, *args, **kw):
        '''
        Initialize filesystem
        '''

        # default option values
        self.driver = 'sqlite3'
        self.database = '/var/lib/bacula/bacula.db'
        self.address = 'localhost'
        self.port = 0
        self.username = 'bacula'
        self.password = ''
        self.conf = '/etc/bacula/bacula-sd.conf'
        self.client = ''
        self.fileset = None
        self.datetime = None
        self.notify = False
        self.pynotify = None
        self.notification = None
        self.dirs = { '/': { '': (FileSystem.null_stat,) } }

        class File (FileSystem._File):
            def __init__(self2, *a, **kw):
                FileSystem._File.__init__(self2, self, *a, **kw)
                
        self.file_class = File
        
        Fuse.__init__(self, *args, **kw)


    def _bacula_stat(self, base64) :
        '''
        Parse base64 encoded lstat info.
        Returns fuse.Stat object with subset of decoded values,
        and dictionary with full list of decoded values
        '''
        st = fuse.Stat()
        lst = dict(zip(FileSystem.bacula_stat_fields, map(self.base64.decode, base64.split())))
        for k in FileSystem.bacula_stat_fields :
            if k in FileSystem.fuse_stat_fields :
                setattr(st, k, lst[k])
        return lst, st

    def _notify(self, message, timeout = -1) :
        '''
        Notify message to user
        '''
        if not self.notify :
            print message
            return

        if not self.notification :
            try :
                import pygtk
                pygtk.require('2.0')
                import pynotify
                self.pynotify = pynotify
            except :
                self.notify = False
                print message
                return
            self.pynotify.init("BaculaFS")
            self.notification = self.pynotify.Notification("BaculaFS", message)
        else :
            self.notification.update("BaculaFS", message)
        self.notification.set_timeout(timeout if timeout >= 0 else self.pynotify.EXPIRES_DEFAULT)
        if not self.notification.show() :
            self.notify = False
            self.notification = None

    def _add_parent_dirs(self, path) :
        '''
        add parent directories of path to dirs dictionary
        '''
        head, tail = os.path.split(path[:-1])
        if not head or head == path:
            return
        head_dir = head if head.endswith('/') else head+'/'
        if not head_dir in self.dirs :
            self.dirs[head_dir] = { tail: (FileSystem.null_stat,) }
        elif not tail in self.dirs[head_dir] :
            self.dirs[head_dir][tail] = (FileSystem.null_stat,)
        self._add_parent_dirs(head_dir)

    
    def fsinit(self):
        '''
        Initialize database, catalog
        '''
        self._notify("Populating file system ... ", 0)

        self.db = Database(self.driver,
                           self.database,
                           self.username,
                           self.password,
                           True)
        self.catalog = Catalog(self.db)
        self.base64 = Base64()
        files = self.catalog.query(self.client, self.fileset, self.datetime)
        self.db = None 
        self.catalog = None

        for file in files :
            # make file entry
            entry = file[2:] + (None,) # stat info placeholder
            head = file[0]
            tail = file[1]
            # handle windows directories
            if not head.startswith('/') :
                head = '/'+head
            # new directory
            if head not in self.dirs :
                self.dirs[head] = {}
            # add parent directories
            self._add_parent_dirs(head)
            # directories are added to their parents
            if tail == '' :
                head, tail = os.path.split(head[:-1])
                if not head.endswith('/') :
                    head += '/'
            # and finally
            self.dirs[head][tail] = entry

        # for dir in self.dirs :
        #     print dir, self.dirs[dir]
            
        self._notify("Ready (%d files)." % len(files))

    def getattr(self, path):
        '''
        Retrieve file attributes.
        Notes:
        1) Bacula does not store attributes for parent directories
           that are not being explicitly backed up, so we provide
           a default set of attributes FileSystem.null_stat
        2) file attributes are base64-encoded and stored by Bacula
           in the catalog. These attributes are decoded when first
           needed and then cached for subsequent requests.
        3) python fuse expects atime/ctime/mtime to be positive
        '''
        head, tail = os.path.split(path)
        #print head, tail
        head = head if head.endswith('/') else head+'/'
        if head in self.dirs and tail in self.dirs[head] :
            attrs = self.dirs[head][tail][-1]
            # decode and cache stat info
            if not attrs :
                self.dirs[head][tail] = self.dirs[head][tail][:-1] + self._bacula_stat(self.dirs[head][tail][-3])
                attrs = self.dirs[head][tail][-1]
            return attrs
        else:
            return -errno.ENOENT
    
    def readdir(self, path, offset):
        path = path if path.endswith('/') else path+'/'
        for key in ['.','..']+self.dirs[path].keys() :
            if len(key) > 0:
                yield fuse.Direntry(key)
            
    def readlink(self, path):
        return -errno.ENOENT

    class _File(object) :
        def __init__(self, fs, path, flags, mode = None) :
            self.fs = fs
            accmode = os.O_RDONLY | os.O_WRONLY | os.O_RDWR
            if (flags & accmode) != os.O_RDONLY:
                raise IOError(errno.EACCES, '')
            raise IOError(errno.ENOENT, '')

        def read(self, size, offset):
            raise IOError(errno.ENOENT, '')

                                                                                                

def main():

    usage = """
baculafs: expose the Bacula catalog as a userspace filesystem

""" + Fuse.fusage

    server = FileSystem(version="%prog " + fuse.__version__, usage=usage)

    server.multithreaded = False

    server.parser.add_option(mountopt="driver", metavar="DRIVER", default=server.driver,
                             help="database driver [default: %default]")
    server.parser.add_option(mountopt="address", metavar="SERVER", default=server.address,
                             help="database server address [default: %default]")
    server.parser.add_option(mountopt="port", metavar="PORT", default=server.port,
                             help="database server port")
    server.parser.add_option(mountopt="database", metavar="PATH", default=server.database,
                             help="database name [default: %default]")
    server.parser.add_option(mountopt="username", metavar="USERNAME", default=server.username,
                             help="database user name [default: %default]")
    server.parser.add_option(mountopt="password", metavar="PASSWORD", default=server.password,
                             help="database password")
    server.parser.add_option(mountopt="conf", metavar="PATH", default=server.conf,
                             help="storage daemon configuration file [default: %default]")
    server.parser.add_option(mountopt="client", metavar="CLIENT", default=server.client,
                             help="file daemon name")
    server.parser.add_option(mountopt="fileset", metavar="FILESET", default=server.fileset,
                             help="fileset")
    server.parser.add_option(mountopt="datetime", metavar="'YYYY-MM-DD hh:mm:ss'", default=server.datetime,
                             help="snapshot date/time [default: now]")
    server.parser.add_option(mountopt="notify", action="store_true", default=server.notify,
                             help="enable notifications [default: %default]")

    server.parse(values=server, errex=1)

    server.main()

        
if __name__ == '__main__':
    sys.exit(main())
